{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735f527-9488-4a7f-a438-fabfa337521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "import tempfile\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc5550-53e8-4fa9-bc5a-9e7ffc06cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_csv(path, index_col='date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    features = df[['vwap', 'dema', 'tema', 'williams', 'rsi', 'minus_10_price', 'minus_5_price', 'minus_4_price', 'minus_3_price', 'minus_2_price']]\n",
    "    target = df[['target']]\n",
    "    \n",
    "    return features, target#, other\n",
    "\n",
    "def normalize_data(train_features, test_features):\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(train_features)\n",
    "\n",
    "    filename = \"alphabet_normalizer.pkl\"\n",
    "    with open(\"../scalers/\" + filename, \"wb\") as file:\n",
    "        pickle.dump(normalizer, file)\n",
    "\n",
    "    train_features_n = normalizer.transform(train_features)\n",
    "    train_features_df = pd.DataFrame(train_features_n, columns=train_features.columns, index=train_features.index)\n",
    "\n",
    "    test_features_n = normalizer.transform(test_features)\n",
    "    test_features_df = pd.DataFrame(test_features_n, columns=test_features.columns, index=test_features.index)\n",
    "\n",
    "    return train_features_df, test_features_df\n",
    "\n",
    "\n",
    "def save_model(model, filename, dir_path):\n",
    "    temp_file = None\n",
    "    try:\n",
    "        # Create a temporary file in the desired directory\n",
    "        temp_file = tempfile.NamedTemporaryFile(dir=dir_path, delete=False)\n",
    "        temp_file.close()  # Close the file so joblib can write to it\n",
    "\n",
    "        # Save the model to the temporary file\n",
    "        joblib.dump(model, temp_file.name)\n",
    "\n",
    "        # Move the temporary file to the final destination\n",
    "        final_path = os.path.join(dir_path, filename)\n",
    "        os.replace(temp_file.name, final_path)\n",
    "        print(f\"Model saved successfully to {final_path}\")\n",
    "\n",
    "        # Verify the file by loading it\n",
    "        loaded_model = joblib.load(final_path)\n",
    "        print(\"Model verified successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "        # Clean up the temporary file if it exists\n",
    "        if temp_file and os.path.exists(temp_file.name):\n",
    "            os.remove(temp_file.name)\n",
    "    finally:\n",
    "        # Ensure the temporary file is removed if it still exists\n",
    "        if temp_file and os.path.exists(temp_file.name):\n",
    "            os.remove(temp_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b8ca2-4009-4480-aea8-bb44b6ae8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Load your stock price dataset\n",
    "    features, target = load_data('../data/clean/alphabet_training_data.csv')\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, shuffle=False)\n",
    "    X_train, X_test = normalize_data(X_train, X_test)\n",
    "    \n",
    "    # Define base models\n",
    "    lin_reg = LinearRegression()\n",
    "    \n",
    "    xgb_reg = xgb.XGBRegressor(\n",
    "        n_estimators=trial.suggest_int('xgb_n_estimators', 50, 500),\n",
    "        max_depth=trial.suggest_int('xgb_max_depth', 3, 9),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-3, 0.3),\n",
    "        subsample=trial.suggest_float('subsample', 0.2, 1.0),\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    svr = SVR(\n",
    "        C=trial.suggest_float('svr_C', 0.1, 10.0),\n",
    "        epsilon=trial.suggest_float('svr_epsilon', 0.01, 1.0),\n",
    "        kernel=trial.suggest_categorical('svr_kernel', ['linear', 'poly', 'rbf'])\n",
    "    )\n",
    "    \n",
    "    # Define meta-model\n",
    "    meta_model = LinearRegression()\n",
    "\n",
    "    # Create the stacking regressor\n",
    "    stacking_reg = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('lin_reg', lin_reg),\n",
    "            ('xgb', xgb_reg),\n",
    "            ('svr', svr)\n",
    "        ],\n",
    "        final_estimator=meta_model\n",
    "    )\n",
    "\n",
    "    # Train the stacking regressor\n",
    "    stacking_reg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = stacking_reg.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Suppress Optuna's logging output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Create and optimize the study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "trial = study.best_trial\n",
    "print(f'Best trial: {trial.number}')\n",
    "print(f'  Value: {trial.value}')\n",
    "print(f'  Params: {trial.params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa3608-319c-4a24-9e13-26aafd9d62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = trial.params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc7ecb-5969-4e55-be41-174ca23c9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = trial.params\n",
    "path = '../data/clean/alphabet_training_data.csv'\n",
    "\n",
    "def prep_data(path):\n",
    "    features, target = load_data(path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, shuffle=False)\n",
    "    X_train, X_test = normalize_data(X_train, X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = prep_data(path)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    n_estimators=best_params['xgb_n_estimators'],\n",
    "    max_depth=best_params['xgb_max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    colsample_bytree=best_params['colsample_bytree'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svr = SVR(\n",
    "    C=best_params['svr_C'],\n",
    "    epsilon=best_params['svr_epsilon'],\n",
    "    kernel=best_params['svr_kernel']\n",
    ")\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Create the stacking regressor\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('lin_reg', lin_reg),\n",
    "        ('xgb', xgb_reg),\n",
    "        ('svr', svr)\n",
    "    ],\n",
    "    final_estimator=meta_model\n",
    ")\n",
    "\n",
    "# Train the stacking regressor\n",
    "stacking_reg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Save the model\n",
    "model_filename = 'alphabet_stacking_regressor_model.pkl'\n",
    "dir_path = \"../models\"\n",
    "save_model(stacking_reg, model_filename, dir_path)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = stacking_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_pred, y_test): .2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_pred, y_test): .2f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred, y_test): .2f}\")\n",
    "print(f\"R2 score:  {stacking_reg.score(X_test, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fbae7f-caba-4e00-a268-a8299144e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = stacking_reg.named_estimators_['xgb'].feature_importances_\n",
    "features = ['vwap', 'dema', 'tema', 'williams', 'rsi', 'minus_10_price', 'minus_5_price', 'minus_4_price', 'minus_3_price', 'minus_2_price']\n",
    "pd.DataFrame(values, features).sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b819f90-1f15-4ae2-8dbc-0978ad2205d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = y_test\n",
    "predictions = pd.DataFrame(y_pred, columns=y_test.columns, index=y_test.index)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Create the subplots\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=False, vertical_spacing=0.1,\n",
    "                    subplot_titles=(\"Prices\", \"\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=actual.index,\n",
    "        y=actual.target,\n",
    "        name='actual'\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    "    secondary_y=False)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=predictions.index,\n",
    "        y=predictions.target,\n",
    "        name='predictions'\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    "    secondary_y=False)\n",
    "\n",
    "fig.update_layout(paper_bgcolor='#e4ecf6')\n",
    "\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"../images/alphabet_pred_actual.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce5701-a631-4b4f-8218-42196fc76c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/clean/alphabet_training_data.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84328c6-6e73-478e-a2cb-2aa9f1b391bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['vwap', 'dema', 'tema', 'williams', 'rsi', 'ratingScore', 'minus_10_price', 'minus_5_price', 'minus_4_price', 'minus_3_price', 'minus_2_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07af28-b3d6-40d7-b558-4e67afd4a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfd390-be2f-4021-bbd7-b0d2be92561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(df_numerical)\n",
    "df_norm = normalizer.transform(df_numerical)\n",
    "df_norm = pd.DataFrame(df_norm, index=df_numerical.index, columns=df_numerical.columns)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd02b41-1500-435d-9c5b-30fe365153d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df_norm, y=df_norm.columns)\n",
    "fig.update_layout(paper_bgcolor='#e4ecf6')\n",
    "fig.show()\n",
    "fig.write_image(\"../images/boxplot_normalized.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-final-project",
   "language": "python",
   "name": "venv-final-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
